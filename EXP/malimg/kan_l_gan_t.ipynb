{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "from kan_convolutional.KANLinear import KANLinear\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional import convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Malimg(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []\n",
    "\n",
    "        for label, subfolder in enumerate(os.listdir(root_dir)):\n",
    "            subfolder_path = os.path.join(root_dir, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                if subfolder not in self.class_names:\n",
    "                    self.class_names.append(subfolder)\n",
    "                label = self.class_names.index(subfolder)\n",
    "                for img_file in os.listdir(subfolder_path):\n",
    "                    if img_file.endswith('.png'):\n",
    "                        self.image_files.append(os.path.join(subfolder_path, img_file))\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "malimg_root_dir = \"C:\\\\Users\\\\Anurag Dutta\\\\Desktop\\\\Essentials\\\\Research\\\\malware\\\\malimg\"\n",
    "gan_generated_root_dir = \"C:\\\\Users\\\\Anurag Dutta\\\\Desktop\\\\Essentials\\\\Research\\\\malware\\\\gan_generated\"\n",
    "\n",
    "malimg_dataset = Malimg(root_dir=malimg_root_dir, transform=transform)\n",
    "gan_generated_dataset = Malimg(root_dir=gan_generated_root_dir, transform=transform)\n",
    "\n",
    "total_malimg_size = len(malimg_dataset)\n",
    "test_size = int(0.2 * total_malimg_size)\n",
    "train_size = total_malimg_size - test_size\n",
    "\n",
    "malimg_train_dataset, malimg_test_dataset = random_split(malimg_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataset = torch.utils.data.ConcatDataset([malimg_train_dataset, gan_generated_dataset])\n",
    "test_dataset = malimg_test_dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinear, self).__init__()\n",
    "        self.kan = KANLinear(\n",
    "            in_features=64 * 64,\n",
    "            out_features=25,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0, 1]\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.kan(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = SimpleLinear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1175, Time elapsed: 147.62 seconds\n",
      "Epoch [2/10], Loss: 0.0120, Time elapsed: 132.43 seconds\n",
      "Epoch [3/10], Loss: 0.0060, Time elapsed: 149.44 seconds\n",
      "Epoch [4/10], Loss: 0.0030, Time elapsed: 127.31 seconds\n",
      "Epoch [5/10], Loss: 0.0021, Time elapsed: 129.00 seconds\n",
      "Epoch [6/10], Loss: 0.0011, Time elapsed: 137.73 seconds\n",
      "Epoch [7/10], Loss: 0.0006, Time elapsed: 150.35 seconds\n",
      "Epoch [8/10], Loss: 0.0004, Time elapsed: 131.38 seconds\n",
      "Epoch [9/10], Loss: 0.0002, Time elapsed: 129.08 seconds\n",
      "Epoch [10/10], Loss: 0.0002, Time elapsed: 130.47 seconds\n",
      "Training completed in: 1364.81 seconds\n",
      "Accuracy: 0.9877, Precision: 0.9724, Recall: 0.9650, F1 Score: 0.9667\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(10): \n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f'Epoch [{epoch + 1}/10], Loss: {running_loss / len(train_loader):.4f}, Time elapsed: {epoch_time:.2f} seconds')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Training completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "torch.save(model.state_dict(), 'kan_l_gan_t_malware_classifier_64x64.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
